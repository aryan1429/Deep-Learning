{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07bc91ac",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2a50496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2682b1f",
   "metadata": {},
   "source": [
    "# Define Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98203552",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5),(0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598fd4a",
   "metadata": {},
   "source": [
    "# Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d01f225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='./data_mnist', download=True, train = True, transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd48d6",
   "metadata": {},
   "source": [
    "# Download Test Datesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "590e284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root='./data_mnist', download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136f1a6",
   "metadata": {},
   "source": [
    "# Step - 4 Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fb311c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = 128, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = 128 , shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230f820",
   "metadata": {},
   "source": [
    "# Build the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3eb559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class denoise_AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,stride=2,padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16,16,3,stride=2,padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16,8,3,stride=2,padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8,16,3,stride=2,padding=1,output_padding=0),   # 4 -> 7\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16,16,3,stride=2,padding=1,output_padding=1),  # 7 -> 14\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16,1,3,stride=2,padding=1,output_padding=1),   # 14 -> 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d759b2e",
   "metadata": {},
   "source": [
    "# Object Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cea1a424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoise_AE(\n",
      "  (enc): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): ConvTranspose2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = denoise_AE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim. Adam(model.parameters(),lr = 0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c09a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    # use same device/shape as img\n",
    "    noise = torch.randn_like(img) * 0.2\n",
    "    noisy_img = img + noise\n",
    "    noisy_img = torch.clamp(noisy_img, 0., 1.)\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ab859",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0c4b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/20], loss:0.0515\n",
      "epoch [2/20], loss:0.0358\n",
      "epoch [3/20], loss:0.0328\n",
      "epoch [4/20], loss:0.0278\n",
      "epoch [5/20], loss:0.0250\n",
      "epoch [6/20], loss:0.0241\n",
      "epoch [7/20], loss:0.0220\n",
      "epoch [8/20], loss:0.0223\n",
      "epoch [9/20], loss:0.0222\n",
      "epoch [10/20], loss:0.0223\n",
      "epoch [11/20], loss:0.0211\n",
      "epoch [12/20], loss:0.0224\n",
      "epoch [13/20], loss:0.0221\n",
      "epoch [14/20], loss:0.0219\n",
      "epoch [15/20], loss:0.0218\n",
      "epoch [16/20], loss:0.0193\n",
      "epoch [17/20], loss:0.0195\n",
      "epoch [18/20], loss:0.0187\n",
      "epoch [19/20], loss:0.0177\n",
      "epoch [20/20], loss:0.0200\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for img,label in train_loader:\n",
    "        img = img.to(device)\n",
    "        noisy_img = add_noise(img)\n",
    "        noisy_img = noisy_img.to(device)\n",
    "        output = model(noisy_img)\n",
    "        loss = criterion(output,img)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1,20,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9a09849",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    img,label = data\n",
    "    img = img.to(device)\n",
    "    noisy_img = add_noise(img)\n",
    "    noisy_img = noisy_img.to(device)\n",
    "    output = model(noisy_img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea8462",
   "metadata": {},
   "source": [
    "# Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc3c6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "show_img = torch.cat([img,noisy_img,output],0)\n",
    "show_img = show_img.cpu().detach()\n",
    "print(show_img.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051f042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
